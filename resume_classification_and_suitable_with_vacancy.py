# -*- coding: utf-8 -*-
"""resume_classification_and_suitable_with_vacancy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d6jvrqrj4dDNQMOIF4fgbBLA7GaEFM19

# **Convert Resume To Text**
"""

!sudo apt install tesseract-ocr

!pip install pytesseract

print("Loading...")
!apt-get install poppler-utils &> /dev/null
!pip install pdf2image &> /dev/null

import pytesseract
import shutil
import os
import random
from pdf2image import convert_from_path
try:
  from PIL import Image
except ImportError:
  import Image

pages = convert_from_path('/content/drive/MyDrive/Kampus Merdeka/Final Project SI-Orbit/classfication text/data/data/ACCOUNTANT/12338274.pdf', 500)
num_pages = 0
#Saving pages in jpeg format
for page in pages:
    page.save('resume_'+str(num_pages)+'.jpg', 'JPEG')
    num_pages += 1

num_pages = 0
extractedInformation = ''
for page in pages:
  image_path_in_colab = ('/content/resume_'+str(num_pages)+'.jpg')
  text = pytesseract.image_to_string(Image.open(image_path_in_colab))
  extractedInformation += text
  num_pages += 1

print(extractedInformation)

"""# **Classify The Resume**"""

import numpy as np 
import pandas as pd 
import re  
import nltk 
nltk.download('stopwords')  
from nltk.corpus import stopwords
import seaborn as sns
import matplotlib.pyplot as plt

data = pd.read_csv("/content/drive/MyDrive/Kampus Merdeka/Final Project SI-Orbit/classfication text/Resume/Resume.csv")
data

data = data.rename(columns={'Category': 'category', 'Resume_str': 'resume'})

data

# Cek jumlah review positive dan negative
plt.figure(figsize=(12,5))
sns.countplot(x='category', data=data)
plt.title('Distribusi class category', fontsize=16)
plt.ylabel('Class Counts', fontsize=16)
plt.xlabel('Class Label', fontsize=16)
plt.xticks(rotation='vertical');

data['category'].unique()

from sklearn.preprocessing import LabelEncoder

X = data['resume'] 
le = LabelEncoder()
le.fit(['HR', 'DESIGNER', 'INFORMATION-TECHNOLOGY', 'TEACHER', 'ADVOCATE',
       'BUSINESS-DEVELOPMENT', 'HEALTHCARE', 'FITNESS', 'AGRICULTURE',
       'BPO', 'SALES', 'CONSULTANT', 'DIGITAL-MEDIA', 'AUTOMOBILE',
       'CHEF', 'FINANCE', 'APPAREL', 'ENGINEERING', 'ACCOUNTANT',
       'CONSTRUCTION', 'PUBLIC-RELATIONS', 'BANKING', 'ARTS', 'AVIATION'])

print(list(le.classes_))
y = le.transform(data['category'])

#y = tweets.iloc[:, 1].values
print(X.shape)
print(X[0])
print(y.shape)
print(y[0])

# Membuat empty List
processed_category = []

for resume in range(0, len(X)):  
    # Hapus semua special characters
    processed_resume = re.sub(r'\W', ' ', str(X[resume]))

    # Hapus semua single characters
    processed_resume = re.sub(r'\s+[a-zA-Z]\s+', ' ', processed_resume)

    # Hapus single characters dari awal
    processed_resume = re.sub(r'\^[a-zA-Z]\s+', ' ', processed_resume) 

    # Substitusi multiple spaces dengan single space
    processed_resume = re.sub(r'\s+', ' ', processed_resume, flags=re.I)

    # Hapus prefixed 'b'
    processed_resume = re.sub(r'^b\s+', '', processed_resume)

    # Ubah menjadi Lowercase
    processed_resume = processed_resume.lower()

    # Masukkan ke list kosong yang telah dibuat sebelumnya
    processed_category.append(processed_resume)

# Cek sebelum cleaning data
print(str(X[:5]))
print()

# Cek setelah cleaning data
processed_category[:5]

from sklearn.feature_extraction.text import TfidfVectorizer
tfidfconverter = TfidfVectorizer(max_features=20000, min_df=5, max_df=0.7, stop_words=stopwords.words('english'),ngram_range=(1,3))
X1 = tfidfconverter.fit_transform(processed_category).toarray()

processed_category

X1

from collections import Counter

counter = Counter(y)
print(counter)

from imblearn.over_sampling import SMOTE
oversample = SMOTE(k_neighbors=5)
X_smote, Y_smote = oversample.fit_resample(X1, y)

from collections import Counter

counter = Counter(Y_smote)
print(counter)

from sklearn.model_selection import train_test_split  
X_train, X_test, y_train, y_test = train_test_split(X_smote, Y_smote, test_size=0.2, random_state=2)

import time

from sklearn.ensemble import RandomForestClassifier

text_classifier_en = RandomForestClassifier(n_estimators=100, random_state=0)
t0_en = time.time()
text_classifier_en.fit(X_train, y_train)
t1_en = time.time()

predictions_en = text_classifier_en.predict(X_test)
t2_en = time.time()
time_linear_train_en = t1_en-t0_en
time_linear_predict_en = t2_en-t1_en

# results
print("EN Training time: %fs; Prediction time: %fs" % (time_linear_train_en, time_linear_predict_en))

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, roc_auc_score

print("Random Forest")
print('Accuracy  = ', round(accuracy_score(y_test, predictions_en)*100,2),'%')
print('Recall    = ', round(recall_score(y_test, predictions_en, average='weighted')*100,2),'%')
print('Precision = ', round(precision_score(y_test, predictions_en, average='weighted')*100,2),'%')
print('F1-Score  = ', round(f1_score(y_test, predictions_en, average='weighted')*100,2),'%')
print("")

# Random Forest
# Input text
review = """
Jameson Gould
City, State Zip Code

T: 000-000-0000

E: email@email.com

Professional Summary
When it comes to financial data analysis and attention to detail, I am more than qualified. In my six years’ experience as a certified accountant, I have excelled in my field, combining diligence with efficiency. As a junior accountant, I communicate well with others to achieve a common task. Bachelor’s degree holder and Certified Management Accountant (CMA). Six years’ professional experience along with two years’ internship experience under a large accounting firm. I take pride in my work and strive to avoid errors made because of simple carelessness.

Work Experience
Junior Accountant2014-present
Expedite data entry efforts and bank reconciliation under the direct guidance of the senior accountant, ensuring clean, accurate financial records.
Process payroll and maintain records for 1099s and other tax documents, providing streamlined, straightforward tax preparation.
Staff Accountant2010-2014
Coordinated data entry with colleagues, ensuring accurate income and spending amounts.
Assisted with payroll account management, filing requisite tax documentation, including W4s and 1099s, among others.
Completed bank reconciliations in a timely manner.
Auditing Clerk2008-2010
Interned with accounting firm specializing in audits and tax preparation.
Developed in-house accounting experience under the guidance of veteran senior accountants while preparing for certification.
Education and Training
Certified Management Accountant (CMA)2010
Association of Accountants and Financial Professionals in Business
Bachelor of Arts in Accounting2008
University of Illinois
Skills
Proficient in computer accounting software, such as QuickBooks, Sage and others.
Professionally and openly communicative, stimulating a productive work environment.
Attentive to detail and computational errors.
Efficient with time constraints, ensuring timeliness without lessening accuracy and thoroughness.
Certified management accountant, complete with two years of on-the-job training and an additional six years of professional accounting experience.
Hobbies and Interests
I lend some of my time to local charities, assisting them with their tax preparations and other accounting needs. On a more personal note, I am an avid game player. From trivial to computational challenges, I always enjoy the thrill of competition. In fact, I have been designing a mathematics-inspired board game during some of my spare time.
"""

review_vector = tfidfconverter.transform([review]).toarray() # vectorizing
pred_text = text_classifier_en.predict(review_vector)
pred_text = le.inverse_transform(pred_text)

#akan menghasilkan prediksi kategori Accountant
print(pred_text[0].capitalize())

# Random Forest
# Input text
review = """
Tony Adams
123 Fake Street, City, State, Zip Code

E: email@email.com P: 000-000-0000

Professional Summary
Dedicated bank teller and loan officer with a solid 12 years of experience in a variety of bank branches and credit unions. Extensive knowledge of the latest banking regulations, rules, and laws in the state of Illinois and Alabama, where I first started my career. Committed to providing customers with top-notch service that exemplifies the bank’s company culture, mission statement, and desire to keep customers banking with us for as long as possible. Remain up to date on the bank’s latest products, such as loans and certificates of deposits, so they can be offered to customers as supplementary services for maximum efficiency and to help them meet their financial goals.

Skills
Superior customer-service and interpersonal skills, which allow me to take proper care of customers and answer all their questions to help them get the most out of the bank’s services.
Advanced math skills for handling large amounts of cash without making mistakes with deposits, withdrawals, and various other business transactions.
Knowledge of the latest accounting and bank teller software and programs.
As a loan officer, initiative is necessary to find new clients, gauge their needs, and act as a solid salesperson.
Highly detail-oriented to ensure all transactions and records are maintained accurately.
Work Experience
Loan Officer-July 2013-Present
Company Name


Reach out to individual customers and companies to see if they have need of a loan.
Gather loan applicant personal and financial information to start the loan process.
Make sure customers understand their loan options as well as the terms and conditions that come with them.
Approve all loan applications before passing them on to management for a final decision.


Head Bank Teller-March 2009-July 2013
Company Name

Oversaw and managed all teller operations for maximum efficiency and customer satisfaction.
Created monthly work schedules and helped train new tellers.
Developed new training method for tellers that reduced customer complaints by 7 percent, increased customer satisfaction by 5 percent, and cut down on wait times by three minutes.


Bank Teller –November 2005-March 2009
Company Name
Counted cash in drawer at the start of shift and again at the end of shift.
Prepared savings bonds, traveler’s checks, money orders, and other types of specialized funds.
Ensured all transactions were properly recorded in bank’s networked computer system for proper recordkeeping.
Ordered bank checks and cards as necessary.

Education
Bachelor’s of Science in Finance2012
Saint City UniversityCity, State
Associate in General Studies2008
Garner Community CollegeCity, State
Hobbies and Interests
I’ve recently started producing and mixing soulful house music and spin at local clubs a few weekends a month. I also teach money management courses at area high schools to teach students how to better manage their money. Participating in a film noir movie club is a new interest of mine I’ve started to explore.
"""

review_vector = tfidfconverter.transform([review]).toarray() # vectorizing
pred_text = text_classifier_en.predict(review_vector)
pred_text = le.inverse_transform(pred_text)

#akan menghasilkan prediksi kategori Banking
print(pred_text[0].capitalize())

"""**Sekarang kita coba Resume yang sudah kita convert dari Image ke Text tadi.**"""

# Random Forest
# Input text
review = extractedInformation

review_vector = tfidfconverter.transform([review]).toarray() # vectorizing
pred_text = text_classifier_en.predict(review_vector)
pred_text = le.inverse_transform(pred_text)
score = round(max(text_classifier_en.predict_proba(review_vector)[0])*100,2)

#akan menghasilkan prediksi Accountant
print(pred_text[0].capitalize())
print('score klasifikasi : ', score, '%',)

"""# **Compare The Resume With Vacancy**

"""

#Install model _md untuk jumlah data yang besar
#!python -m spacy download en_core_web_md

import re  
import nltk 
nltk.download('stopwords')

from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
nltk.download('punkt')

# Import library Spacy, library untuk melakukan proses yang ada di dalam domain nlp
from spacy.lang.en.stop_words import STOP_WORDS
from string import punctuation

texts = extractedInformation

keyword = """
Accountant responsibilities include:
Tracking payments to internal and external stakeholders
Preparing budget forecasts
Processing tax payments and returns
accountant job description

Job brief
We are looking for an Accountant to manage all financial transactions, from fixed payments and variable expenses to bank deposits and budgets.

Accountant responsibilities include auditing financial documents and procedures, reconciling bank statements and calculating tax payments and returns. To be successful in this role, you should have previous experience with bookkeeping and a flair for spotting numerical mistakes.

Ultimately, you will provide us with accurate quantitative information on financial position, liquidity and cash flows of our business, while ensuring we’re compliant with all tax regulations.

Responsibilities
Manage all accounting transactions
Prepare budget forecasts
Publish financial statements in time
Handle monthly, quarterly and annual closings
Reconcile accounts payable and receivable
Ensure timely bank payments
Compute taxes and prepare tax returns
Manage balance sheets and profit/loss statements
Report on the company’s financial health and liquidity
Audit financial transactions and documents
Reinforce financial data confidentiality and conduct database backups when necessary
Comply with financial policies and regulations
Requirements
Work experience as an Accountant
Excellent knowledge of accounting regulations and procedures, including the Generally Accepted Accounting Principles (GAAP)
Hands-on experience with accounting software like FreshBooks and QuickBooks
Advanced MS Excel skills including Vlookups and pivot tables
Experience with general ledger functions
Strong attention to detail and good analytical skills
BSc in Accounting, Finance or relevant degree
Additional certification (CPA or CMA) is a plus.
"""

import spacy

#Bisa mengunnakan _sm atau _md
nlp = spacy.load('en_core_web_sm')

from nltk.stem import WordNetLemmatizer
import nltk
nltk.download('wordnet')

# Memasukkan daftar stopword ke dalam variabel stopwords
stopwords = list(STOP_WORDS)
print(stopwords)

# Punctuation = karakter khusus, karakter ini akan dihilangkan dari teks
punctuation = punctuation + '\n'
punctuation

# Membuat token dari teks
doc = nlp(texts)
tokens = [token.text for token in doc]
print(tokens)

# Membuat dictionary bag of word
word_frequencies = {}
 
# Mengisi word_frequencies tanpa stopword dan karakter khusus
for word in doc:
    if word.text.lower() not in stopwords:
        if word.text.lower() not in punctuation:
            if word.text not in word_frequencies.keys():
                word_frequencies[word.text] = 1
            else:
                word_frequencies[word.text] += 1
                
print(word_frequencies)

# a denotes adjective in "pos"
lemmatizer = WordNetLemmatizer()

doc1 = list(word_frequencies.keys())
doc1 = [lemmatizer.lemmatize(word, pos='a') for word in doc1]
doc1 = [lemmatizer.lemmatize(word, pos='v') for word in doc1]
doc1 = [lemmatizer.lemmatize(word, pos='n') for word in doc1]
doc1

def listToString(s): 
    # initialize an empty string
    str1 = "" 
    # traverse in the string  
    for ele in s: 
        str1 += " "+ele  
    # return string  
    return str1

doc1 = listToString(doc1)
print(doc1)

processed_tweet = re.sub(r'\W', ' ', doc1)
# Hapus semua single characters
processed_tweet = re.sub(r'\s+[a-zA-Z]\s+', ' ', processed_tweet)
# Hapus single characters dari awal
processed_tweet = re.sub(r'\^[a-zA-Z]\s+', ' ', processed_tweet) 
# Substitusi multiple spaces dengan single space
processed_tweet= re.sub(r'\s+', ' ', processed_tweet, flags=re.I)
# Hapus prefixed 'b'
processed_tweet = re.sub(r'^b\s+', '', processed_tweet)

processed_tweet = re.sub(r'\d', '', processed_tweet)
# Ubah menjadi Lowercase
processed_tweet1 = processed_tweet.lower()

print(processed_tweet1)

# Membuat token dari teks
doc2 = nlp(keyword)
tokens = [token.text for token in doc2]
print(tokens)

# Membuat dictionary bag of word
word_frequencies2 = {}

# Mengisi word_frequencies tanpa stopword dan karakter khusus
for word in doc2:
    if word.text.lower() not in stopwords:
        if word.text.lower() not in punctuation:
            if word.text not in word_frequencies2.keys():
                word_frequencies2[word.text] = 1
            else:
                word_frequencies2[word.text] += 1
                
print(word_frequencies2)

# a denotes adjective in "pos"
doc2 = list(word_frequencies2.keys())

doc2 = [lemmatizer.lemmatize(word, pos='a') for word in doc2]
doc2 = [lemmatizer.lemmatize(word, pos='v') for word in doc2]
doc2 = [lemmatizer.lemmatize(word, pos='n') for word in doc2]
doc2

def listToString(s): 
    # initialize an empty string
    str1 = "" 
    # traverse in the string  
    for ele in s: 
        str1 += " "+ele  
    # return string  
    return str1

doc2 = listToString(doc2)
print(doc2)

processed_tweet = re.sub(r'\W', ' ', doc2)
# Hapus semua single characters
processed_tweet = re.sub(r'\s+[a-zA-Z]\s+', ' ', processed_tweet)
# Hapus single characters dari awal
processed_tweet = re.sub(r'\^[a-zA-Z]\s+', ' ', processed_tweet) 
# Substitusi multiple spaces dengan single space
processed_tweet= re.sub(r'\s+', ' ', processed_tweet, flags=re.I)
# Hapus prefixed 'b'
processed_tweet = re.sub(r'^b\s+', '', processed_tweet)

processed_tweet = re.sub(r'\d', '', processed_tweet)

# Ubah menjadi Lowercase
processed_tweet2 = processed_tweet.lower()

print(processed_tweet2)

# Program to measure the similarity between 
# two sentences using cosine similarity.
# X = input("Enter first string: ").lower()
# Y = input("Enter second string: ").lower()
from nltk.corpus import stopwords

# tokenization
X_list = word_tokenize(processed_tweet1) 
Y_list = word_tokenize(processed_tweet2)
  
# sw contains the list of stopwords
sw = stopwords.words('english') 
l1 =[];l2 =[]
  
# remove stop words from the string
X_set = {w for w in X_list if not w in sw} 
Y_set = {w for w in Y_list if not w in sw}
  
# form a set containing keywords of both strings 
rvector = X_set.union(Y_set) 
for w in rvector:
    if w in X_set: l1.append(1) # create a vector
    else: l1.append(0)
    if w in Y_set: l2.append(1)
    else: l2.append(0)
c = 0
  
# cosine formula 
for i in range(len(rvector)):
        c+= l1[i]*l2[i]
cosine = round(c / float((sum(l1)*sum(l2))**0.5)*100, 2)
print("score kemiripan : ", cosine, '%')

avg_score = round(((score+cosine) / 2),2)
print('Kecocokan resume dengan job vacancy :',avg_score,'%')